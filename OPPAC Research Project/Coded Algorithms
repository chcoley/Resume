from math import floor
import math
import numpy as np
import matplotlib.pyplot as plt
#function created to use as function in bisection algorithm 
def f(x):
    return math.cos(0.5*(x**2))
#a and b serve as start and end point on line
#tol serves as a margin of error we must be within to find an accurate enough answer 
def bisection(a,b,tol):
    #keep track of iterations
    i=0
    #Error statement for requirements for algorithm to work
    if f(a)*f(b)>=0:
        print("Need valid a and b where F(a)*F(b)<0")
        return
    #while loop to see if we have reached tolerance
    while b - a >= tol:
        #bisection is done and new start/end point is found for next iteration
        c = (a+b)/2
        if (f(c) == 0):
            break
        if (f(a) * f(c) < 0):
            b = c
        else:
            a = c
        i=i+1
    print("The root is: " + str(c) + ". The number of iterations is: "+str(i))
a = 5.1
b = 5.7
bisection(a,b,0.01)
#function created to serve as function used in secant algorithm
def g(x):
    g = math.cos(0.5*(x**2))
    return g

def secant(x1,x2, tol):
    n = 0; xm = 0; x0 = 0; z = 0
    #make sure requirements for secant method are met
    if (g(x1) * g(x2) < 0):
        #keeps track of iterations
        while n<100:
            #secant method is performed
            xm = (x2 - g(x2) * (x2 - x1)/(g(x2) - g(x1)))
            c = g(x1) * g(x0)
            x1=x2
            x2=xm
            n += 1
            if (c == 0):
                break
            (x2 - g(x2) * (x2 - x1)/(g(x2) - g(x1)))
            if(abs(x2 - x1) < tol):
                break
        print("The root of this equation: " + str(xm) + ". The number of iterations is: " + str(n))
    else:
        print("Cannot find root")
secant(5.1, 5.7, 0.0001)
#SIR model using self created data/weights
def SIR(days):
    #weights/rates for Infection, Death, Recovery
    beta = 0.001
    gamma = 0.05
    mu = 0.03
    Sval = [1000]
    Ival = [1]
    Rval = [0]
    Dval = [0]
    xval = [0]
    #starting population with patient 0 at I 
    S = 1000
    I = 1
    R = 0
    D = 0
    i = 0 

    while days>i:
        newI = floor(min(max(beta*I*S,0), S))
        newR = floor(min(max(gamma*I, 0), I))
        newD = floor(min(max(mu*I,0), I-newR))
        S = S - newI
        I = I + newI - newR - newD
        R = R + newR
        D = D + newD
        Sval.append(S)
        Ival.append(I)
        Rval.append(R)
        Dval.append(D)
        xval.append(i)
        i=i+1
    #plotting of graph showing trends for each group
    plt.plot(xval, Sval, label = "S")
    plt.plot(xval, Ival, label = "I")
    plt.plot(xval, Rval, label = "R")
    plt.plot(xval, Dval, label = "D")
    plt.show()
SIR(100)

#function created to use as function for cobweb algorithm
def f(x, r):
    return r*x*(1-x)

def cobweb(f, r, x0):
    x = np.linspace(0, 1, 100)
    #plotting function
    plt.plot(x, f(x, r))
    plt.plot(x, x)

    valx, valy = np.empty((2,51,2))
    valx[0] = x0
    valy[0] = 0
    #keeps track of iterations, making sure not to over/under fit
    for n in range(1, 50, 2):
        valx[n] = valx[n-1]
        valy[n] = f(valx[n-1], r)
        valx[n+1] = valy[n]
        valy[n+1] = valy[n]
    #plots cobweb
    plt.plot(valx, valy)
cobweb(f, 2.8, 0.2)

#need a jpg image for singular value decomposition 
import cv2
def SVD(valsRetained):
    imagePath = './Landscape.jpg'
    image = cv2.imread(imagePath, 0)
    # Must be less than smaller dimension
    U, D, VT = np.linalg.svd(image)
    m,n = image.shape
    print(m,n)
    y=len(VT[1])
    #creating empty matrices to fill with retained values 
    redU = np.zeros((m,valsRetained))
    redD = np.zeros((m,m))
    sigma = np.zeros((valsRetained,valsRetained))
    redVT = np.zeros((valsRetained,n))
    #filling our matrices with new retained values to recreate image
    for i in range(0,valsRetained):
        redU[:,i]= U[:,i]
        sigma[i,i] =D[i]
        redVT[i,:] = VT[i,:]
    print(redVT)
    print(sigma)
    print(redU)
    #new image, should be less visible depending on how big matrices dimensions are
    cv2.imwrite('./reducedLandscape.jpg', redU.dot(sigma.dot(redVT)))
SVD(30)

def Lloyds(k, max_iter = 10):
    c = 0
    seed = 1800
    np.random.seed(seed)
    numPoints = 100
    #initializing centroid starting coordinates
    centroids = np.zeros((4,2))
    centroids[0][0] = 2.0
    centroids[0][1] = 1.0
    centroids[1][0] = 0.0
    centroids[1][1] = 2.0
    centroids[2][0] = -2.0
    centroids[2][1] = -1.0
    centroids[3][0] = 0.0
    centroids[3][1] = -2.0
    data = np.zeros((numPoints, 2))
    #array used to assing color to each centroid
    col_array = ["red", "yellow", "green", "orange"]
    cluster = np.zeros(len(data))
    mindist = np.zeros(len(data))
    #initializing random data point locations so that we can then use Lloyds algorithm to create clusters
    for point in range(numPoints):
        centroid = centroids[np.random.randint(4)][:]
        data[point][:] = np.random.normal(centroid, 0.5, 2)
    #plotting random data points 
    plt.scatter(data[:,0], data[:,1])
    rand_cen = np.zeros((k,2))
    for point in range(k):
        rand_cen[point][:] = np.random.uniform(-3,3,2)
    for y in range(0,k):
        plt.scatter(rand_cen[y,0], rand_cen[y,1], marker='x', color = col_array[y])
    #while loop to make sure we iterate as instructed 
    while c<max_iter:
        #tracking distance from random points to each centroid to see which centroid its closest to
        for m in range(0, max_iter):
            rdist_x, rdist_y = 0,0
            ydist_x, ydist_y = 0,0
            gdist_x, gdist_y = 0,0
            odist_x, odist_y = 0,0
            r, y, g, o = 0,0,0,0
            for i in range(0, len(data)):
                distances = np.zeros(k)
                #distance formula implemented and values stored to later take smallest one
                for j in range(0, k):
                    distances[j] = np.sqrt(np.sum(np.power(data[i, :] - rand_cen[j], 2))) 
                #smallest value indext is stored so proper centroid color can be assigned
                cluster[i] = np.argmin(distances)
                mindist[i] = distances[np.argmin(distances)]
        #proper centroid color is assigned
        for i in range(0, (len(cluster))):
            col = col_array[int(cluster[i])]
            plt.scatter(data[i,0], data[i,1], color = str(col))
        cluster = [int(x) for x in cluster]
        #for loop used to keep track of average distance between centroid and all points assigned to it
        for i in range(len(data)):
            if(cluster[i] == 0):
                rdist_x = rdist_x + data[i][0]
                rdist_y = rdist_y + data[i][1]
                r=r+1
            if(cluster[i] == 1):
                ydist_x = ydist_x + data[i][0]
                ydist_y = ydist_y + data[i][1]
                y=y+1
            if(cluster[i] == 2):
                gdist_x = gdist_x + data[i][0]
                gdist_y = gdist_y + data[i][1]
                g=g+1
            if(cluster[i] == 3):
                odist_x = odist_x + data[i][0]
                odist_y = odist_y + data[i][1]
                o=o+1
        for i in range(0,k):
            if(i == 0):
                rand_cen[i][0] = rdist_x/r
                rand_cen[i][1] = rdist_y/r
            if(i == 1):
                rand_cen[i][0] = ydist_x/y
                rand_cen[i][1] = ydist_y/y
            if(i == 2):
                rand_cen[i][0] = gdist_x/g
                rand_cen[i][1] = gdist_y/g
            if(i == 3):
                rand_cen[i][0] = odist_x/o
                rand_cen[i][1] = odist_y/o
        #plotting centroids in new locations with their assigned data points and correct colors 
        for y in range(0,k):
            plt.scatter(rand_cen[y,0], rand_cen[y,1], marker='x', color = col_array[y])
        c=c+1
Lloyds(4)

#function defined to use as function for Lagrange Formula
def f(X):
    return ((1+np.cos(np.pi*X))/2)

def Lagrange(n):
    x = np.arange(-1,1,(2/n))
    xp = np.arange(-1,1,0.01)
    y=[]
    for i in x:
        y.append(f(i))
    yp = [0.0*x for x in xp]
    for i in range(n):
        p = 1
        for j in range(n):
            if i != j:
                p = p * (xp - x[j])/(x[i] - x[j])
        yp = yp + p * y[i]
    plt.scatter(x,y)
    plt.plot(xp, f(xp))
    plt.plot(xp,yp)
Lagrange(10)

#Cellular Automata algorithm
def CA(n, numDays):
    sequence = "000000000010000000000"
    rules = ["111","110","101","100","011","010","001","000"]
    BN = bin(n).replace("0b", "")
    while(len(BN)<8):
        BN = "0" + BN
    for i in range(0,numDays):
        update=""
        #used to monitor rules applied to each binary sequence 
        for i in range(0,len(sequence)):
            if(i==0 and sequence[i]=="0" and sequence[i+1]=="0"):
                update = update + BN[7]
            if(i==0 and sequence[i]=="1" and sequence[i+1]=="0"):
                update = update + BN[2]
            if(i==0 and sequence[i]=="0" and sequence[i+1]=="1"):
                update = update + BN[6]
            if(i==0 and sequence[i]=="1" and sequence[i+1]=="1"):
                update = update = BN[4]
            if(i>0 and i<(len(sequence)-1)):
                update = update + BN[rules.index(sequence[i-1:i+2])]
            if(i==(len(sequence)-1) and sequence[i-1]=="0" and sequence[i]=="0"):
                update = update + BN[7]
            if(i==(len(sequence)-1) and sequence[i-1]=="1" and sequence[i]=="0"):
                update = update + BN[3]
            if(i==(len(sequence)-1) and sequence[i-1]=="0" and sequence[i]=="1"):
                update = update + BN[5]
            if(i==(len(sequence)-1) and sequence[i-1]=="1" and sequence[i]=="1"):
                update = update = BN[1]
        print(sequence)
        print(update)
    print(BN)
CA(101,5)
